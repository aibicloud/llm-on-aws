{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a81a1c0c-e878-4f7f-aae2-a3646494a8d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "default_bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "region = sess._region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6d7cfc-b940-415a-bfcd-3861e16d71c8",
   "metadata": {},
   "source": [
    "## Edit code artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4adb2eb-e882-4d77-a6e5-98f21e6b69fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engine=Python\n",
      "option.tensor_parallel_degree=1\n",
      "# option.model_id=LinkSoul/Chinese-Llama-2-7b\n",
      "option.s3url=s3://genai.piyao.com/llm/meta-llama/Llama-2-7b-chat-hf/"
     ]
    }
   ],
   "source": [
    "# use huggingface model_id or s3url\n",
    "!cat llama_2_model/serving.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef7e630-1706-46a7-a513-ac8625008a38",
   "metadata": {},
   "source": [
    "## Construct artifacts and deploy to SageMaker endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68a3c862-a19e-4755-821b-00702c887f30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama_2_model/\n",
      "llama_2_model/model.py\n",
      "llama_2_model/model.py.backup\n",
      "llama_2_model/serving.properties\n",
      "llama_2_model/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "# Construct code artifacts tar\n",
    "code_tarname = 'llama_2_model' # llama_2_model\n",
    "\n",
    "!rm -rf {code_tarname}.tar.gz\n",
    "!rm -rf {code_tarname}/.ipynb_checkpoints\n",
    "!tar czvf {code_tarname}.tar.gz {code_tarname}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa9214c8-b22d-43a4-9acd-1e6cbe17c255",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tmp06/v2-2023-08-29-02-34-24-715'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.utils.name_from_base(\"tmp06/v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "955fce1c-e119-4e4f-ae57-c50568d04e94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify a inference container version, \n",
    "# form - https://github.com/aws/deep-learning-containers/blob/master/available_images.md#large-model-inference-containers\n",
    "inference_image_uri = f\"727897471807.dkr.ecr.{region}.amazonaws.com.cn/djl-inference:0.22.1-deepspeed0.8.3-cu118\"\n",
    "# inference_image_uri = f\"768219110428.dkr.ecr.cn-northwest-1.amazonaws.com.cn/sm-tgi100-winston:latest\"\n",
    "\n",
    "# copy the code tar to 'any' valid S3 path (different from hf model artifacts), use default bucket here\n",
    "s3_code_artifact = sess.upload_data(f\"{code_tarname}.tar.gz\", \n",
    "                                    default_bucket, \n",
    "                                    sagemaker.utils.name_from_base(\"tmp06/v2\"))\n",
    "\n",
    "# name a SageMaker Endpoint\n",
    "endpoint_name = sagemaker.utils.name_from_base(code_tarname.replace('_','-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9938ebc8-96cf-4799-8dd8-5838a28efd19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'727897471807.dkr.ecr.cn-northwest-1.amazonaws.com.cn/djl-inference:0.22.1-deepspeed0.8.3-cu118'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_image_uri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b733c70d-272a-4bf0-8b80-7f05222efef6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------"
     ]
    }
   ],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "\n",
    "model = Model(image_uri=inference_image_uri,\n",
    "              model_data=s3_code_artifact, \n",
    "              role=role)\n",
    "\n",
    "model.deploy(initial_instance_count = 1,\n",
    "             instance_type = 'ml.g4dn.4xlarge', \n",
    "             endpoint_name = endpoint_name,\n",
    "             container_startup_health_check_timeout = 2900\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8169509-5b7b-47f8-a634-7a3b68429eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5789d8b8-dde4-48ce-9786-9a14c591b17e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845310af-ef49-4fff-9ba4-a60835854f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4152e2c8-53fd-4429-9484-e51e1e29a25e",
   "metadata": {},
   "source": [
    "## Wrap a predictor and request specified endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74dfa03d-318e-4a4a-8892-c0a250765d44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import serializers, deserializers\n",
    "\n",
    "# endpoint_name = 'llama-2-model-2023-08-28-09-26-16-994'\n",
    "\n",
    "predictor = sagemaker.Predictor(\n",
    "            endpoint_name=endpoint_name,\n",
    "            sagemaker_session=sess,\n",
    "            serializer=serializers.JSONSerializer(),\n",
    "            deserializer=deserializers.JSONDeserializer(),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c691bb4d-124c-4f5a-a22c-dbcfae44b4a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] <<SYS>>\n",
      "\n",
      "\n",
      "<</SYS>>\n",
      "\n",
      "you should use the knowledge provided to answer user's question.  \n",
      "the knowledge you known are: [21] after modification.\n",
      "\n",
      "The ABTS+ radical reaction solution configuration was as follows: 5 mL of 7 mmol/L of ABTS and 5 mL of 2.45 mmol/L of potassium persulfate were mixed and stored in the dark for 12 h. Before use, 0.1 mol/L of pH 7.4 phosphate buffer saline (PBS) was added to dilute until the OD734 value was 0.70 ± 0.02.\n",
      "\n",
      "The sample solution was the same as that of the EPS sample solution measured by DPPH clearing ability.\n",
      "question: how to config the ABTS  radical reaction  ? [/INST]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': '  Based on the information provided, the ABTS radical reaction configuration is as follows:\\n1. Start with 5 mL of 7 mmol/L ABTS solution.\\n2. Add 5 mL of 2.45 mmol/L potassium persulfate solution to the ABTS solution.\\n3. Mix the solutions in the dark for 12 hours.\\n4. Before use, dilute the reaction mixture with 0.1 mol/L pH 7.4 phosphate buffer saline (PBS) to achieve an OD734 value of 0.70 ± 0.02.\\nSo, the final configuration for the ABTS radical reaction is:\\nABTS solution: 5 mL of 7 mmol/L ABTS\\nPotassium persulfate solution: 5 mL of 2.45 mmol/L K2S2O8\\nDilution: 0.1 mol/L pH 7.4 PBS\\nTime: 12 hours in the dark\\nOD734 value: 0.70 ± 0.02'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "system_prompt = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "ask = \"\"\"\n",
    "you should use the knowledge provided to answer user's question.  \n",
    "the knowledge you known are: [21] after modification.\\n\\nThe ABTS+ radical reaction solution configuration was as follows: 5 mL of 7 mmol/L of ABTS and 5 mL of 2.45 mmol/L of potassium persulfate were mixed and stored in the dark for 12 h. Before use, 0.1 mol/L of pH 7.4 phosphate buffer saline (PBS) was added to dilute until the OD734 value was 0.70 ± 0.02.\\n\\nThe sample solution was the same as that of the EPS sample solution measured by DPPH clearing ability.\n",
    "question: how to config the ABTS  radical reaction  ? \n",
    "\"\"\"\n",
    "\n",
    "def get_prompt(message: str, chat_history: list[tuple[str, str]]) -> str:\n",
    "    texts = [f'[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n']\n",
    "    for user_input, response in chat_history:\n",
    "        texts.append(f'{user_input.strip()} [/INST] {response.strip()} </s><s> [INST] ')\n",
    "    texts.append(f'{message.strip()} [/INST]')\n",
    "    return ''.join(texts)\n",
    "\n",
    "ask = get_prompt(ask, [])\n",
    "print(ask)\n",
    "\n",
    "predictor.predict(\n",
    "    {\"ask\": ask, \"parameters\": {\"max_new_tokens\": 300}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6275329f-3925-4880-8fcf-1ba411d8bd37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': ''}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful, respectful and honest assistant. you should use the knowledge provided to answer user's question.  \n",
    "the knowledge you known are: [21] after modification.\\n\\nThe ABTS+ radical reaction solution configuration was as follows: 5 mL of 7 mmol/L of ABTS and 5 mL of 2.45 mmol/L of potassium persulfate were mixed and stored in the dark for 12 h. Before use, 0.1 mol/L of pH 7.4 phosphate buffer saline (PBS) was added to dilute until the OD734 value was 0.70 ± 0.02.\\n\\nThe sample solution was the same as that of the EPS sample solution measured by DPPH clearing ability.\n",
    "question: how to config the ABTS  radical reaction  ? \n",
    "\"\"\"\n",
    "\n",
    "predictor.predict(\n",
    "    {\"ask\": system_prompt, \"parameters\": {\"max_new_tokens\": 300}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fbc276e-5ae3-4a8c-9f69-4a97db56d9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.73 s ± 0 ns per loop (mean ± std. dev. of 1 run, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n3 -r1\n",
    "predictor.predict(\n",
    "    {\"inputs\": \"in order to make a good pizza, i need to \", \"parameters\": {\"max_new_tokens\": 200}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b00c5773-846b-4132-a862-a21006c9e536",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de7e361e-f9ba-4768-b150-f825011d944f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "            If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "def get_prompt(message: str, chat_history: list[tuple[str, str]]) -> str:\n",
    "    texts = [f'[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n']\n",
    "    for user_input, response in chat_history:\n",
    "        texts.append(f'{user_input.strip()} [/INST] {response.strip()} </s><s> [INST] ')\n",
    "    texts.append(f'{message.strip()} [/INST]')\n",
    "    return ''.join(texts)\n",
    "\n",
    "\n",
    "# prompt = system_prompt.format(\"who are you?\")\n",
    "`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb8019f0-822e-4de0-9a61-ab7ea67773ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': \"As an AI language model, I don't have an age. I am a computer program that processes and generates text based on the input I receive. I don't age in the way that humans do, and I don't have a physical form. \"}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt\n",
    "texts = get_prompt(\"how old are you?\", [])\n",
    "# texts\n",
    "response = predictor.predict(\n",
    "    {\"ask\": texts, \"parameters\": {\n",
    "        \"do_sample\": True,\n",
    "        \"max_new_tokens\": 100,\n",
    "        \"temperature\": 0.5,\n",
    "        # \"return_text\": True,\n",
    "        # \"return_full_text\": False\n",
    "    }}\n",
    ")\n",
    "\n",
    "response\n",
    "\n",
    "# answer_text\n",
    "# outputs.add_as_json({\"answer\": answer_text})\n",
    "# outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a3d5239-b929-48e8-b48c-df2771267580",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'getattr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgetattr\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'getattr'"
     ]
    }
   ],
   "source": [
    "import getattr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4584d5cf-cd5e-4869-8849-7cd32c5eda0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
