{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b11b798-9db6-4d89-9f7f-f42268892ac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "default_bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "region = sess._region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d1ec53-b454-479e-a4f4-2b6b2c3a568a",
   "metadata": {},
   "source": [
    "# Edit code artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc533067-0a6d-4b73-bb03-49fe2f645c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engine=Python\n",
      "option.tensor_parallel_degree=1\n",
      "#option.model_id=TheBloke/Wizard-Vicuna-7B-Uncensored-HF\n",
      "option.s3url=s3://sagemaker-us-east-1-629244530291/LLM-RAG/workshop/LLMA2_001_model/"
     ]
    }
   ],
   "source": [
    "# use huggingface model_id or s3url\n",
    "!cat acc_wizard_model/serving.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d44650-1486-4992-a4c7-987a08bcdc51",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Construct artifacts and deploy to SageMaker endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12f81bc3-5d05-4bbe-a8b6-7df565670e96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_wizard_model/\n",
      "acc_wizard_model/model.py\n",
      "acc_wizard_model/serving.properties\n",
      "acc_wizard_model/inference.py\n",
      "acc_wizard_model/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "# Construct code artifacts tar\n",
    "code_tarname = 'acc_wizard_model'\n",
    "\n",
    "!rm -rf {code_tarname}.tar.gz\n",
    "!rm -rf {code_tarname}/.ipynb_checkpoints\n",
    "!tar czvf {code_tarname}.tar.gz {code_tarname}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff40824d-94b7-4922-a456-f2b74d67286e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-cn-northwest-1-768219110428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'llama2-2023-08-20-01-11-05-endpoint'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify a inference container version, \n",
    "# form - https://github.com/aws/deep-learning-containers/blob/master/available_images.md#large-model-inference-containers\n",
    "# inference_image_uri = f\"096331988441.dkr.ecr.us-east-1.amazonaws.com/sm-tgi100-winston:latest\"\n",
    "inference_image_uri = f\"768219110428.dkr.ecr.cn-northwest-1.amazonaws.com.cn/sm-tgi100-winston:latest\"\n",
    "# copy the code tar to 'any' valid S3 path (different from hf model artifacts), use default bucket here\n",
    "s3_code_artifact = sess.upload_data(f\"{code_tarname}.tar.gz\", \n",
    "                                    default_bucket, \n",
    "                                    sagemaker.utils.name_from_base(\"tmp06/v2\"))\n",
    "\n",
    "print(default_bucket)\n",
    "# %%\n",
    "model_name = \"llama2-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "# name a SageMaker Endpoint\n",
    "endpoint_name = model_name + '-endpoint'\n",
    "\n",
    "\n",
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3741fc7f-d914-49c7-a286-fb11f5b3c9e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---"
     ]
    }
   ],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "hub = {\n",
    "    'HF_MODEL_ID':'LinkSoul/Chinese-Llama-2-7b', # LinkSoul/Chinese-Llama-2-7b    TheBloke/Llama-2-7B-Chat-GGML\n",
    "    'HUGGING_FACE_HUB_TOKEN':'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',\n",
    "}\n",
    "\n",
    "\n",
    "model = Model(image_uri=inference_image_uri,\n",
    "              model_data=s3_code_artifact, \n",
    "              env=hub,\n",
    "              role=role,\n",
    "              name=model_name)\n",
    "\n",
    "model.deploy(initial_instance_count = 1,\n",
    "             instance_type = 'ml.g4dn.8xlarge', \n",
    "             endpoint_name = endpoint_name,\n",
    "             container_startup_health_check_timeout = 3600\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9150782c-85bc-4a33-8733-bda1bf7ab30d",
   "metadata": {},
   "source": [
    "# Wrap a predictor and request specified endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90c94895-4934-4d20-a54a-054771675801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import serializers, deserializers\n",
    "\n",
    "# endpoint_name = 'llama2-2023-08-01-14-56-00-endpoint'\n",
    "\n",
    "predictor = sagemaker.Predictor(\n",
    "            endpoint_name=endpoint_name,\n",
    "            sagemaker_session=sess,\n",
    "            serializer=serializers.JSONSerializer(),\n",
    "            deserializer=deserializers.JSONDeserializer(),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52758d8e-d119-4c73-b968-1d193fcdfdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "            If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "def get_prompt(message: str, chat_history: list[tuple[str, str]]) -> str:\n",
    "    texts = [f'[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n']\n",
    "    for user_input, response in chat_history:\n",
    "        texts.append(f'{user_input.strip()} [/INST] {response.strip()} </s><s> [INST] ')\n",
    "    texts.append(f'{message.strip()} [/INST]')\n",
    "    return ''.join(texts)\n",
    "\n",
    "\n",
    "prompt = system_prompt.format(\"who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a6347a-a9f0-4903-aba3-c6827b68a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = get_prompt(\"什么是夫妻肺片？\", [])\n",
    "\n",
    "predictor.predict(\n",
    "    {\"inputs\": prompt, \"parameters\": {\n",
    "        \"do_sample\": False,\n",
    "        \"max_new_tokens\": 100,\n",
    "        \"temperature\": 0.01,\n",
    "        \"watermark\": True,\n",
    "        \"enable_streaming\": True\n",
    "    }}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee20f0fd-ec8c-46e5-8c0a-6e13ca66c593",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80e4439-33fe-4de9-ab55-1474028acd06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
